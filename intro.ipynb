{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (1.23.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/home/danial/PycharmProjects/MIR-HWs3-5/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.9/site-packages (1.4.3)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./venv/lib/python3.9/site-packages (from pandas) (1.23.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./venv/lib/python3.9/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas) (2022.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/home/danial/PycharmProjects/MIR-HWs3-5/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Requirement already satisfied: openpyxl in ./venv/lib/python3.9/site-packages (3.0.10)\r\n",
      "Requirement already satisfied: et-xmlfile in ./venv/lib/python3.9/site-packages (from openpyxl) (1.1.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/home/danial/PycharmProjects/MIR-HWs3-5/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.9/site-packages (3.7)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.9/site-packages (from nltk) (2022.6.2)\r\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.9/site-packages (from nltk) (1.1.0)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from nltk) (4.64.0)\r\n",
      "Requirement already satisfied: click in ./venv/lib/python3.9/site-packages (from nltk) (8.1.3)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/home/danial/PycharmProjects/MIR-HWs3-5/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Collecting sklearn\r\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\r\n",
      "Collecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 30.8 MB 159 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting scipy>=1.3.2\r\n",
      "  Downloading scipy-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 42.2 MB 150 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17.3 in ./venv/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.23.0)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\r\n",
      "Collecting threadpoolctl>=2.0.0\r\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\r\n",
      "Building wheels for collected packages: sklearn\r\n",
      "  Building wheel for sklearn (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=ab7756eca0b4a264dd9898d09879c8fc8ae764117a5938d2e8d4f58cddd4691f\r\n",
      "  Stored in directory: /home/danial/.cache/pip/wheels/e4/7b/98/b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\r\n",
      "Successfully built sklearn\r\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\r\n",
      "Successfully installed scikit-learn-1.1.1 scipy-1.8.1 sklearn-0.0 threadpoolctl-3.1.0\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/home/danial/PycharmProjects/MIR-HWs3-5/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install nltk\n",
    "!pip install sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n"
     ]
    },
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWDC.xlsx: (2080, 19)\n",
      "spaceX.xlsx: (2010, 19)\n",
      "Google.xlsx: (2051, 19)\n",
      "Meta.xlsx: (1644, 19)\n",
      "metaverse.xlsx: (1553, 19)\n",
      "Apple.xlsx: (2031, 19)\n",
      "instagram.xlsx: (1949, 19)\n",
      "Microsoft.xlsx: (2080, 19)\n",
      "Twitter.xlsx: (1616, 19)\n",
      "facebook.xlsx: (2027, 19)\n",
      "Amazon.xlsx: (2078, 19)\n",
      "nvidia.xlsx: (2010, 19)\n",
      "Tesla.xlsx: (2004, 19)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in os.listdir(\"./Excels\"):\n",
    "    df = pd.read_excel(os.path.join(\"./Excels\", file))\n",
    "    dfs.append(df)\n",
    "    print(file, end=\": \")\n",
    "    print(df.shape)\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(Index(['Tweet Id', 'Text', 'Name', 'Screen Name', 'UTC', 'Created At',\n        'Favorites', 'Retweets', 'Language', 'Client', 'Tweet Type', 'URLs',\n        'Hashtags', 'Mentions', 'Media Type', 'Media URLs', 'Unnamed: 16',\n        'Unnamed: 17', 'Unnamed: 18'],\n       dtype='object'),\n (25133, 19))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = df[df['Language'] == 'en']\n",
    "df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def text_to_words(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\n",
    "    \"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\",\n",
    "    \"\", text)\n",
    "    text = re.sub(\"#\\w+\", \"\", text)\n",
    "    text = re.sub(\"@\\w+\", \"\", text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word for word in words if word not in stopwords.words('english') and word.isalpha()]\n",
    "    return words\n",
    "df['Text_words'] = df['Text'].apply(text_to_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[('rt', 8640),\n ('amp', 1744),\n ('new', 1247),\n ('join', 1132),\n ('video', 1129),\n ('campaign', 924),\n ('microsoft', 837),\n ('us', 834),\n ('latest', 778),\n ('follow', 748),\n ('technology', 747),\n ('environments', 746),\n ('testing', 675),\n ('skills', 668),\n ('apple', 667),\n ('unique', 657),\n ('airdrop', 657),\n ('rtx', 655),\n ('mr', 649),\n ('heroes', 646)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(df['Text_words'].explode()).most_common(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danial/PycharmProjects/MIR-HWs3-5/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1330: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vocabulary = list(set(df['Text_words'].explode()) - {np.nan})\n",
    "\n",
    "tfidf = TfidfVectorizer(vocabulary=vocabulary)\n",
    "tfidf_tran=tfidf.fit_transform(df['Text_words'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "\n",
    "def gen_vector_T(tokens):\n",
    "    Q = np.zeros((len(vocabulary)))\n",
    "    x= tfidf.transform(tokens)\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            ind = vocabulary.index(token)\n",
    "            Q[ind]  = x[0, tfidf.vocabulary_[token]]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    return Q\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    if sum(a) == 0 or sum(b) == 0:\n",
    "        return -1\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "def cosine_similarity_T(k, query):\n",
    "    #print(\"Cosine Similarity\")\n",
    "    tokens = text_to_words(query)\n",
    "    print(tokens)\n",
    "    q_df = pd.DataFrame(columns=['q_clean'])\n",
    "    q_df.loc[0, 'q_clean'] = tokens\n",
    "    # q_df['q_clean'] = wordLemmatizer(q_df.q_clean)\n",
    "\n",
    "    d_cosines = []\n",
    "\n",
    "    query_vector = gen_vector_T(tokens)\n",
    "    for d in tfidf_tran.A:\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "\n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "    a = pd.DataFrame()\n",
    "    for i, index in enumerate(out):\n",
    "        a.loc[i, 'index'] = str(index)\n",
    "        a.loc[i, 'text'] = df.iloc[index]['Text']\n",
    "        a.loc[i, 'words'] = str(df.iloc[index]['Text_words'])\n",
    "        a.loc[i, 'Score'] = d_cosines[int(index)]\n",
    "    return a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elon', 'musk']\n"
     ]
    },
    {
     "data": {
      "text/plain": "   index                                               text  \\\n0   1817  @SpaceX + @DogelonMars = 🚀\\n\\n@elonmusk  Don't...   \n1   1811  RT @ElonMartians : @SpaceX + @DogelonMars = 🚀\\...   \n2   1813  RT @ElonMartians : @SpaceX + @DogelonMars = 🚀\\...   \n3   1814  RT @ElonMartians : @SpaceX + @DogelonMars = 🚀\\...   \n4  15901  @elonmusk @elonamuskjet @ElonMuskNewsOrg @Tesl...   \n5   2813  RT @Dyoungelonhero : Elon,Send #GalaxyHeroes t...   \n6   2583  RT @Dyoungelonhero : Elon,Send #GalaxyHeroes t...   \n7   2158  RT @Dyoungelonhero : Elon,Send #GalaxyHeroes t...   \n8   2131  In Elon We Trust! ❤️🙏🏼  #dogecoin #tesla #Spac...   \n9  14730  Could Elon Musk be a thief? Elon Musk why don'...   \n\n                                               words     Score  \n0                                           ['elon']  1.000000  \n1                                     ['rt', 'elon']  0.949679  \n2                                     ['rt', 'elon']  0.949679  \n3                                     ['rt', 'elon']  0.949679  \n4                                 ['elon', 'spacex']  0.668938  \n5                             ['rt', 'elon', 'send']  0.615394  \n6                             ['rt', 'elon', 'send']  0.615394  \n7                             ['rt', 'elon', 'send']  0.615394  \n8                                  ['elon', 'trust']  0.530308  \n9  ['could', 'elon', 'musk', 'thief', 'elon', 'mu...  0.485152  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>words</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1817</td>\n      <td>@SpaceX + @DogelonMars = 🚀\\n\\n@elonmusk  Don't...</td>\n      <td>['elon']</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1811</td>\n      <td>RT @ElonMartians : @SpaceX + @DogelonMars = 🚀\\...</td>\n      <td>['rt', 'elon']</td>\n      <td>0.949679</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1813</td>\n      <td>RT @ElonMartians : @SpaceX + @DogelonMars = 🚀\\...</td>\n      <td>['rt', 'elon']</td>\n      <td>0.949679</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1814</td>\n      <td>RT @ElonMartians : @SpaceX + @DogelonMars = 🚀\\...</td>\n      <td>['rt', 'elon']</td>\n      <td>0.949679</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15901</td>\n      <td>@elonmusk @elonamuskjet @ElonMuskNewsOrg @Tesl...</td>\n      <td>['elon', 'spacex']</td>\n      <td>0.668938</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2813</td>\n      <td>RT @Dyoungelonhero : Elon,Send #GalaxyHeroes t...</td>\n      <td>['rt', 'elon', 'send']</td>\n      <td>0.615394</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2583</td>\n      <td>RT @Dyoungelonhero : Elon,Send #GalaxyHeroes t...</td>\n      <td>['rt', 'elon', 'send']</td>\n      <td>0.615394</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2158</td>\n      <td>RT @Dyoungelonhero : Elon,Send #GalaxyHeroes t...</td>\n      <td>['rt', 'elon', 'send']</td>\n      <td>0.615394</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2131</td>\n      <td>In Elon We Trust! ❤️🙏🏼  #dogecoin #tesla #Spac...</td>\n      <td>['elon', 'trust']</td>\n      <td>0.530308</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14730</td>\n      <td>Could Elon Musk be a thief? Elon Musk why don'...</td>\n      <td>['could', 'elon', 'musk', 'thief', 'elon', 'mu...</td>\n      <td>0.485152</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_T(10, \"elon musk\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "vocabulary = list(set(df['Text_words'].explode()) - {np.nan})\n",
    "vocabulary_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "mat = np.zeros((len(df), len(vocabulary)), )\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for token in row['Text_words']:\n",
    "        mat[index][vocabulary_index[token]] = 1\n",
    "\n",
    "\n",
    "def boolean_search(query):\n",
    "    #print(\"Cosine Similarity\")\n",
    "    tokens = text_to_words(query)\n",
    "    query_vector = []\n",
    "    for token in tokens:\n",
    "        if token in vocabulary_index:\n",
    "            query_vector.append(vocabulary_index[token])\n",
    "    out = []\n",
    "    for index, vec in enumerate(mat):\n",
    "        flag = True\n",
    "        for token_index in query_vector:\n",
    "            if vec[token_index] == 0:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            out.append(index)\n",
    "    print(out)\n",
    "    a = pd.DataFrame()\n",
    "    for i, index in enumerate(out):\n",
    "        a.loc[i, 'index'] = str(index)\n",
    "        a.loc[i, 'text'] = df.iloc[index]['Text']\n",
    "        a.loc[i, 'words'] = str(df.iloc[index]['Text_words'])\n",
    "\n",
    "    return a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 93, 350, 1495, 1517, 1531, 1543, 1547, 1548, 1549, 1550, 1551, 1589, 1652, 1680, 1694, 1780, 1783, 1801, 1809, 1844, 1859, 1866, 1897, 1900, 1954, 1993, 1999, 2029, 2037, 2042, 2066, 2072, 2083, 2084, 2086, 2103, 2107, 2108, 2128, 2132, 2133, 2137, 2146, 2147, 2149, 2151, 2153, 2154, 2161, 2172, 2174, 2175, 2181, 2200, 2203, 2206, 2223, 2239, 2260, 2265, 2273, 2281, 2294, 2337, 2393, 2396, 2421, 2422, 2423, 2429, 2446, 2448, 2449, 2472, 2475, 2610, 2663, 2690, 2693, 2700, 2733, 2763, 2780, 2784, 2812, 2814, 2819, 2821, 2832, 2834, 2835, 2848, 2861, 2867, 2869, 2870, 2880, 2897, 2928, 2949, 2955, 3003, 3107, 6047, 11057, 11698, 14423, 14439, 14459, 14479, 14499, 14502, 14504, 14517, 14518, 14532, 14549, 14554, 14555, 14556, 14557, 14558, 14559, 14620, 14628, 14629, 14636, 14640, 14644, 14722, 14730, 14784, 14796, 14811, 14816, 14832, 14858, 14872, 14908, 14928, 14939, 14980, 14986, 14988, 14997, 15069, 15109, 15110, 15169, 15201, 15203, 15205, 15209, 15232, 15233, 15234, 15241, 15282, 15299, 15302, 15303, 15314, 15334, 15335, 15411, 15503, 15529, 15584, 15585, 15590, 15591, 15596, 15599, 15602, 15648, 15706, 15708, 15715, 15784, 15798, 15801, 15808, 15818, 15819, 15862, 15903, 15907, 15978]\n"
     ]
    },
    {
     "data": {
      "text/plain": "     index                                               text  \\\n0       22  Elon Musk give me  MONEY bitch And don't forge...   \n1       93  Elon Musk give me  $10,000 AND Putin a giant s...   \n2      350  Elon Musk give me  $99,000 AND Putin elegant a...   \n3     1495  what if Gerald Cotten is Elon Musk (:)\\n@elonm...   \n4     1517  Elon Musk's SpaceX has cleared a huge obstacle...   \n..     ...                                                ...   \n184  15819  Elon Musk Sends Companywide Email Praising Tes...   \n185  15862  RT @EveryElonReply : Elon Musk liked a tweet f...   \n186  15903  RT @EveryElonReply : Elon Musk liked a tweet f...   \n187  15907  .\\n.\\nElon Musk on Life\\n...The Universe and E...   \n188  15978  RT @kirillklip : Elon Musk And #Lithium: \"Salt...   \n\n                                                 words  \n0    ['elon', 'musk', 'give', 'money', 'bitch', 'fo...  \n1    ['elon', 'musk', 'give', 'putin', 'giant', 'sp...  \n2    ['elon', 'musk', 'give', 'putin', 'elegant', '...  \n3         ['gerald', 'cotten', 'elon', 'musk', 'musk']  \n4    ['elon', 'musk', 'spacex', 'cleared', 'huge', ...  \n..                                                 ...  \n184  ['elon', 'musk', 'sends', 'companywide', 'emai...  \n185  ['rt', 'elon', 'musk', 'liked', 'tweet', 'tesl...  \n186  ['rt', 'elon', 'musk', 'liked', 'tweet', 'eli'...  \n187  ['elon', 'musk', 'life', 'universe', 'everythi...  \n188  ['rt', 'elon', 'musk', 'salt', 'salad', 'looks...  \n\n[189 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22</td>\n      <td>Elon Musk give me  MONEY bitch And don't forge...</td>\n      <td>['elon', 'musk', 'give', 'money', 'bitch', 'fo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>93</td>\n      <td>Elon Musk give me  $10,000 AND Putin a giant s...</td>\n      <td>['elon', 'musk', 'give', 'putin', 'giant', 'sp...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>350</td>\n      <td>Elon Musk give me  $99,000 AND Putin elegant a...</td>\n      <td>['elon', 'musk', 'give', 'putin', 'elegant', '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1495</td>\n      <td>what if Gerald Cotten is Elon Musk (:)\\n@elonm...</td>\n      <td>['gerald', 'cotten', 'elon', 'musk', 'musk']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1517</td>\n      <td>Elon Musk's SpaceX has cleared a huge obstacle...</td>\n      <td>['elon', 'musk', 'spacex', 'cleared', 'huge', ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>15819</td>\n      <td>Elon Musk Sends Companywide Email Praising Tes...</td>\n      <td>['elon', 'musk', 'sends', 'companywide', 'emai...</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>15862</td>\n      <td>RT @EveryElonReply : Elon Musk liked a tweet f...</td>\n      <td>['rt', 'elon', 'musk', 'liked', 'tweet', 'tesl...</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>15903</td>\n      <td>RT @EveryElonReply : Elon Musk liked a tweet f...</td>\n      <td>['rt', 'elon', 'musk', 'liked', 'tweet', 'eli'...</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>15907</td>\n      <td>.\\n.\\nElon Musk on Life\\n...The Universe and E...</td>\n      <td>['elon', 'musk', 'life', 'universe', 'everythi...</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>15978</td>\n      <td>RT @kirillklip : Elon Musk And #Lithium: \"Salt...</td>\n      <td>['rt', 'elon', 'musk', 'salt', 'salad', 'looks...</td>\n    </tr>\n  </tbody>\n</table>\n<p>189 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_search(\"Elon Musk\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}